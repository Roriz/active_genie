name: Benchmark

on:
  release:
    types: [released]

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}

jobs:
  benchmark:
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        model:
          - provider: openai
            name: gpt-4.1-mini
          - provider: google
            name: gemini-2.5-flash-preview-05-20
          - provider: anthropic
            name: claude-3-5-haiku-20241022
          - provider: deepseek
            name: deepseek-chat
        module: [extractor, scorer, comparator, ranker, lister]
    env:
      MODEL: ${{ matrix.model.name }}
      PROVIDER_NAME: ${{ matrix.model.provider }}
      MODULE: ${{ matrix.module }}

    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: '3.2'
        bundler-cache: true

    - name: Run ${{ matrix.module }}
      run: |
        touch test_output.tmp
        bundle exec rake active_genie:benchmark[${{ matrix.module }}] | tee >(cat) > test_output.tmp
        output=$(cat test_output.tmp)
        rm test_output.tmp
        echo ""
        result_line=$(echo "$output" | grep -E '[0-9]+ runs, [0-9]+ assertions, [0-9]+ failures, [0-9]+ errors, [0-9]+ skips' | tail -1)
        if [ -n "$result_line" ]; then
          runs=$(echo $result_line | grep -oE '[0-9]+ runs' | grep -oE '[0-9]+')
          failures=$(echo $result_line | grep -oE '[0-9]+ failures' | grep -oE '[0-9]+')
          errors=$(echo $result_line | grep -oE '[0-9]+ errors' | grep -oE '[0-9]+')
          skips=$(echo $result_line | grep -oE '[0-9]+ skips' | grep -oE '[0-9]+')
          successes=$((runs - failures - errors - skips))
          precision=$(($successes*100/$runs))
          duration=$(echo "$output" | grep -oE 'Finished in [0-9]+\.[0-9]+s' | grep -oE '[0-9]+\.[0-9]+')
        fi

        all_llm_usage=$(cat log/active_genie.log | grep "llm_usage" | jq -r '.total_tokens')
        requests=$(echo "$all_llm_usage" | wc -l)
        total_tokens=0
        for llm_stat in $all_llm_usage; do
          total_tokens=$((total_tokens + llm_stat))
        done

        avg_duration=$(awk "BEGIN {printf \"%.2f\", $duration/$runs}")

        touch benchmark/latest-${{ matrix.module }}-${{ matrix.model.provider }}-${{ matrix.model.name }}.csv
        echo "${{ matrix.module }},${{ matrix.model.provider }},${{ matrix.model.name }},$successes/$failures ($runs),$precision,$duration,$requests,$total_tokens,$avg_duration" >> benchmark/latest-${{ matrix.module }}-${{ matrix.model.provider }}-${{ matrix.model.name }}.csv

        touch benchmark/latest.md
        echo "| ActiveGenie::Module | Provider | Model | Tests (Total/Success/Fails) | Precision | Duration (s) | Requests | Tokens | Avg. Duration (s) |" >> benchmark/latest.md
        echo "|--- |--- |--- |--- |--- |--- |--- |--- |--- |" >> benchmark/latest.md
        echo "| ${{ matrix.module }} | ${{ matrix.model.provider }} | ${{ matrix.model.name }} | $successes/$failures ($runs) | $precision | $duration | $requests | $total_tokens | $avg_duration |" >> benchmark/latest.md

        cat benchmark/latest.md

        if [ $total_tokens -eq 0 ]; then
          exit 1
        fi

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: latest-${{ matrix.module }}-${{ matrix.model.provider }}-${{ matrix.model.name }}-benchmark
        path: benchmark/latest-${{ matrix.module }}-${{ matrix.model.provider }}-${{ matrix.model.name }}.csv
        retention-days: 1
        overwrite: true
        if-no-files-found: ignore

  build_report:
    runs-on: ubuntu-latest
    needs: [benchmark]
    steps:
    - uses: actions/checkout@v4

    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: benchmark/artifacts

    - name: Build consolidated report
      run: |
        mkdir -p benchmark/reports

        # Create header for the consolidated CSV report
        echo "Module,Provider,Model,Tests,Precision,Duration,Requests,Tokens,Avg_Duration" > benchmark/benchmark.csv

        # Create header for the markdown report
        echo "# Benchmark Results" > benchmark/benchmark.md
        echo "" >> benchmark/benchmark.md
        echo "| Module | Provider | Model | Tests | Precision | Duration (s) | Requests | Tokens | Avg. Duration (s) |" >> benchmark/benchmark.md
        echo "|--------|----------|-------|-------|-----------|--------------|----------|--------|-------------------|" >> benchmark/benchmark.md

        # Process all CSV files and build the consolidated reports
        find benchmark/artifacts -name "*.csv" -type f | while read -r file; do
          tail "$file" >> benchmark/benchmark.csv

          line=$(cat "$file")
          IFS=',' read -r module provider model tests precision duration requests tokens avg_duration <<< "$line"
          echo "| $module | $provider | $model | $tests | $precision | $duration | $requests | $tokens | $avg_duration |" >> benchmark/benchmark.md
        done

        cat benchmark/benchmark.md
        echo "$(cat benchmark/benchmark.md)" >> $GITHUB_STEP_SUMMARY

    - name: Upload consolidated report
      uses: actions/upload-artifact@v4
      with:
        name: benchmark
        path: benchmark/benchmark.*
        retention-days: 7
