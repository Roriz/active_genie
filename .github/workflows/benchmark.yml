name: Benchmark

on:
  workflow_dispatch:

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}

jobs:
  benchmark:
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        model:
          - provider: openai
            name: gpt-5-mini
          - provider: openai
            name: gpt-5-nano
          - provider: google
            name: gemini-2.5-flash
          - provider: google
            name: gemini-2.5-flash-lite
          - provider: anthropic
            name: claude-3-5-haiku-20241022
          - provider: deepseek
            name: deepseek-chat
        module: [extractor, scorer, comparator, ranker, lister]
    env:
      MODEL: ${{ matrix.model.name }}
      PROVIDER_NAME: ${{ matrix.model.provider }}
      MODULE: ${{ matrix.module }}

    steps:
    - uses: actions/checkout@v4

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: '3.2'
        bundler-cache: true

    - name: Run ${{ matrix.module }}
      env:
        MODEL: ${{ matrix.model.name }}
        PROVIDER_NAME: ${{ matrix.model.provider }}
        MODULE: ${{ matrix.module }}
        TESTOPTS: "-j 10"
      run: bin/benchmark_and_report

    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: latest-${{ matrix.module }}-${{ matrix.model.provider }}-${{ matrix.model.name }}-benchmark
        path: benchmark/latest-${{ matrix.module }}-${{ matrix.model.provider }}-${{ matrix.model.name }}.csv
        retention-days: 1
        overwrite: true
        if-no-files-found: ignore

  build_report:
    runs-on: ubuntu-latest
    needs: [benchmark]
    steps:
    - uses: actions/checkout@v4

    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: benchmark/artifacts

    - name: Build consolidated report
      run: |
        mkdir -p benchmark/reports

        # Create header for the consolidated CSV report
        echo "Module,Provider,Model,Tests,Precision,Duration,Requests,Tokens,Avg_Duration" > benchmark/benchmark.csv

        # Create header for the markdown report
        echo "# Benchmark Results" > benchmark/benchmark.md
        echo "" >> benchmark/benchmark.md
        echo "| Module | Provider | Model | Tests | Precision | Duration (s) | Requests | Tokens | Avg. Duration (s) |" >> benchmark/benchmark.md
        echo "|--------|----------|-------|-------|-----------|--------------|----------|--------|-------------------|" >> benchmark/benchmark.md

        # Process all CSV files and build the consolidated reports
        find benchmark/artifacts -name "*.csv" -type f | while read -r file; do
          tail "$file" >> benchmark/benchmark.csv

          line=$(cat "$file")
          IFS=',' read -r module provider model tests precision duration requests tokens avg_duration <<< "$line"
          echo "| $module | $provider | $model | $tests | $precision | $duration | $requests | $tokens | $avg_duration |" >> benchmark/benchmark.md
        done

        cat benchmark/benchmark.md
        echo "$(cat benchmark/benchmark.md)" >> $GITHUB_STEP_SUMMARY

    - name: Upload consolidated report
      uses: actions/upload-artifact@v4
      with:
        name: benchmark
        path: benchmark/benchmark.*
        retention-days: 7
